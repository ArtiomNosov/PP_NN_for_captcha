{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# либы"
      ],
      "metadata": {
        "id": "QlWeO8Bahf4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lion_pytorch"
      ],
      "metadata": {
        "id": "bIhN0zxystJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ede231f-c041-4d34-b05f-6ff6bcff7b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lion_pytorch\n",
            "  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from lion_pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion_pytorch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion_pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion_pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion_pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->lion_pytorch) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->lion_pytorch) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->lion_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->lion_pytorch) (1.3.0)\n",
            "Installing collected packages: lion_pytorch\n",
            "Successfully installed lion_pytorch-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import path\n",
        "from imageio.v2 import imread\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torch.optim import *\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from lion_pytorch import Lion\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations\n",
        "import albumentations.pytorch\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import font_manager, rc\n",
        "from IPython import display\n",
        "import random\n",
        "import glob\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import warnings\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import gc\n",
        "import random\n",
        "import urllib.request\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Version of Torch : {0}\".format(torch.__version__))\n",
        "print(\"Version of TorchVision : {0}\".format(torchvision.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul5-L7cmw11R",
        "outputId": "89a49d89-d88f-4667-a61f-49f7d04e3ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version of Torch : 2.0.1+cu118\n",
            "Version of TorchVision : 0.15.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# функции для обработки+ начальные параметры"
      ],
      "metadata": {
        "id": "4IO3HrCoilwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = [\"/content/drive/MyDrive/lfnfn2\"]\n",
        "\n",
        "import os\n",
        "\n",
        "# Device\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "print(\"Device : {0}\".format(\"GPU\" if USE_CUDA else \"CPU\"))\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "\n",
        "# Train\n",
        "EPOCHS = 6\n",
        "BATCH_SIZE = 20\n",
        "START_EPOCH = 1\n",
        "\n",
        "lr = 0.0001\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "MAX_LEN = 10\n",
        "\n",
        "transformer = transforms.Compose([transforms.ToTensor(),#обработка: 256*256 и нормализация изображения\n",
        "                                  torchvision.transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
        "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                 ])\n",
        "\n"
      ],
      "metadata": {
        "id": "mCAqpZXUrPBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e8200c-8a61-4a1c-f102-96069e650267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device : CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_tensor_to_plt(img):\n",
        "    img = img.detach().numpy()[0]\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    return img\n",
        "\n",
        "def get_image(file: str) -> np.ndarray: #возвращает матрицу из пикселей\n",
        "\n",
        "\n",
        "    img_file = path.expanduser(file)\n",
        "    image = imread(img_file)\n",
        "\n",
        "    return image\n",
        "\n",
        "def show(matrix: np.ndarray, colored=False) -> None: #показывает фото\n",
        "\n",
        "    cmap = plt.get_cmap('viridis') if colored else plt.get_cmap('gray')\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.imshow(matrix, cmap=cmap)\n",
        "    plt.show()\n",
        "\n",
        "def rgba_to_rgb(matrix):#rgba image to rgb\n",
        "    rows, cols, _ = matrix.shape\n",
        "    new_matrix = np.zeros((rows, cols, 3), dtype=int)\n",
        "\n",
        "    color_range = 255 if np.max(matrix) > 1 else 1 # maximum value of color\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            k = matrix[i][j][3] / color_range\n",
        "            new_matrix[i][j] = [\n",
        "                matrix[i][j][0] * k,\n",
        "                matrix[i][j][1] * k,\n",
        "                matrix[i][j][2] * k,\n",
        "            ]\n",
        "\n",
        "    return new_matrix\n",
        "\n",
        "def image_to_black_and_white(matrix): #rgb to black and while\n",
        "\n",
        "\n",
        "    rows, cols, _ = matrix.shape\n",
        "    new_matrix = np.zeros(matrix.shape[:2], dtype=int)\n",
        "    print(new_matrix)\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            new_matrix[i][j] = (min(matrix[i][j]) + max(matrix[i][j])) / 2\n",
        "\n",
        "    return new_matrix\n",
        "\n",
        "def image_normalization(matrix): #нормализация (0, 1)\n",
        "\n",
        "    if np.max(matrix) > 1:\n",
        "        return matrix / 255\n",
        "\n",
        "    return matrix\n",
        "\n",
        "def image_noise_reduction(matrix): #убирает шумы\n",
        "\n",
        "    matrix = image_normalization(matrix)\n",
        "\n",
        "    return (matrix + 1) / 2\n",
        "\n",
        "def image_to_mask(matrix, k): # convert b/w image to binary colored mask\n",
        "\n",
        "    matrix = image_normalization(matrix)\n",
        "\n",
        "    rows, cols = matrix.shape\n",
        "    new_matrix = np.zeros(matrix.shape, dtype=float)\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            new_matrix[i][j] = 1 if matrix[i][j] >= k else 0\n",
        "\n",
        "    return new_matrix\n",
        "\n",
        "def transform(image, k): #применение всех функций\n",
        "\n",
        "\n",
        "    if image.shape[2] == 4:\n",
        "        image = rgba_to_rgb(image)\n",
        "\n",
        "    image = image_to_black_and_white(image)\n",
        "\n",
        "    image = image_normalization(image)\n",
        "\n",
        "    image = image_noise_reduction(image)\n",
        "\n",
        "    image = image_to_mask(image, k)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "t_PgCuDuwyuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "special_char_list = [\"<pad>\"] # [\"<unk>\", \"<pad>\"]\n",
        "num_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "upper_alphabet_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "lower_alphabet_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "string_list = special_char_list + num_list + upper_alphabet_list + lower_alphabet_list\n",
        "CHAR_NUM = len(string_list)\n",
        "\n",
        "token_dictionary = {i : string_list[i] for i in range(len(string_list))}\n",
        "reversed_token_dictionary = {v: k for k, v in token_dictionary.items()}\n",
        "\n",
        "#токенизация и замена переменных на цифры"
      ],
      "metadata": {
        "id": "mp-Idoi1otNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# класс датасет"
      ],
      "metadata": {
        "id": "eC8A4tQol0j3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#создание класса дататсет\n",
        "class ImageToTextDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.path = path\n",
        "\n",
        "        self.transformer = transform\n",
        "\n",
        "        self.file = []\n",
        "        for dirpath, _, filenames in os.walk(\"/content/drive/MyDrive/lfnfn2\"):\n",
        "            for i in filenames:\n",
        "              self.file.append(\"/content/drive/MyDrive/lfnfn2/\"+i)\n",
        "\n",
        "        self.num = len(self.file)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num\n",
        "\n",
        "    def transform(self, image):\n",
        "        if self.transformer!=None:\n",
        "            return self.transformer(image)\n",
        "        else :\n",
        "            return image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.file[idx]\n",
        "\n",
        "        Y = []\n",
        "        for char in list(filename.split(\"/\")[-1].split(\".\")[0]):\n",
        "            Y.append(reversed_token_dictionary[char])\n",
        "\n",
        "        if len(Y) < MAX_LEN:\n",
        "            Y += [reversed_token_dictionary[\"<pad>\"]]*(MAX_LEN-len(Y))\n",
        "\n",
        "        img = cv2.imread(self.file[idx])\n",
        "        try:\n",
        "            sketch_image = cv2.cvtColor(img[:,:256,:], cv2.COLOR_BGR2RGB)\n",
        "        except:\n",
        "            print(self.file[idx])\n",
        "        X = self.transform(sketch_image)\n",
        "\n",
        "        Y_tensor_list = []\n",
        "        for y_ind in Y:\n",
        "            y_tensor = torch.zeros(CHAR_NUM)\n",
        "            y_tensor[y_ind] = 1\n",
        "            Y_tensor_list.append(y_tensor.unsqueeze(0))\n",
        "\n",
        "        return X, torch.tensor(Y), torch.tensor(Y)"
      ],
      "metadata": {
        "id": "j0XnBZXFzmyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1=ImageToTextDataset(DATASET_PATH,  transform=transformer)\n",
        "data2=ImageToTextDataset(DATASET_PATH,  transform=transformer)"
      ],
      "metadata": {
        "id": "DVpbvOQVr0Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(data1, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(data2, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "Q_OQtLTtqRgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# нейросеть lacc и функции к ней"
      ],
      "metadata": {
        "id": "kXKMjl6wmW4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LACC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = torchvision.models.efficientnet_v2_m().features\n",
        "        self.converter = nn.parameter.Parameter(torch.ones(64, CHAR_NUM))\n",
        "\n",
        "        self.silu = nn.SiLU()\n",
        "        self.linear1 = nn.Linear(1280, 512)\n",
        "        self.linear2 = nn.Linear(512, 64)\n",
        "        self.linear3 = nn.Linear(64, MAX_LEN)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature = self.encoder(x)\n",
        "        #print(feature.shape)\n",
        "        feature = torch.flatten(feature, start_dim=2)\n",
        "        #print(feature.shape)\n",
        "        feature = torch.matmul(feature, self.converter)\n",
        "\n",
        "        y = feature.transpose(-1, -2)\n",
        "        y = self.linear1(y)\n",
        "        y = self.silu(y)\n",
        "        y = self.linear2(y)\n",
        "        y = self.silu(y)\n",
        "        y = self.linear3(y)\n",
        "#silu https://paperswithcode.com/method/silu\n",
        "# 3 линейных слоя и сигмоидная функция активации\n",
        "        return y"
      ],
      "metadata": {
        "id": "GhB-rXcqruR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LACC().to(device)"
      ],
      "metadata": {
        "id": "PghZIas5sPya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Lion(model.parameters(), lr=lr, weight_decay=1e-2) #оптимизатор lion https://github.com/lucidrains/lion-pytorch\n",
        "criterion = nn.CrossEntropyLoss() #cross entropy -функция потерь\n",
        "\n",
        "def calculate_loss(predict, y):\n",
        "    return criterion(predict, y)\n",
        "\n",
        "\n",
        "def getSimilar(list1, list2):\n",
        "    correct = 0\n",
        "    for item1, item2 in zip(list1, list2):\n",
        "        if item1==item2:\n",
        "            correct += 1\n",
        "    return correct\n",
        "\n",
        "def getCorrect(list1, list2):\n",
        "    if ''.join(map(str,list1))==''.join(map(str,list2)):\n",
        "        return 1\n",
        "    else :\n",
        "        return 0\n",
        "\n",
        "def evalSample(model, x, target, batch=0):\n",
        "    def replaceSpeicalToken(text):\n",
        "        text = text.replace('<pad>','□')\n",
        "        text = text.replace('<unk>','?')\n",
        "        return text\n",
        "\n",
        "    x, target = x.to(device), target.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    predict = model(x[batch].unsqueeze(0))\n",
        "    predict = F.log_softmax(predict, dim=-2)\n",
        "    predict = torch.argmax(predict, dim=-2)\n",
        "\n",
        "    predict_text = \"\"\n",
        "    for token in predict[0].to(cpu_device).tolist():\n",
        "\n",
        "        predict_text += str(token_dictionary[token])\n",
        "\n",
        "    target_text = \"\"\n",
        "    for token in target[0].to(cpu_device).tolist():\n",
        "        target_text += str(token_dictionary[token])\n",
        "\n",
        "    predict_text = replaceSpeicalToken(predict_text)\n",
        "    target_text = replaceSpeicalToken(target_text)\n",
        "\n",
        "\n",
        "    return predict_text, target_text\n",
        "\n",
        "def train_one_epoch(model, optimizer, train_dataloader, test_dataloader, epoch=None):\n",
        "    train_loss = 0.0\n",
        "    test_loss = 0.0\n",
        "    accurate = 0.0\n",
        "    hard_accurate = 0.0\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    for x, y, label_target in train_dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        predict = model(x)\n",
        "        predict = F.log_softmax(predict, dim=-2)\n",
        "        predict_text = torch.argmax(predict, dim=-2)\n",
        "\n",
        "        loss = calculate_loss(predict, y)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Testing\n",
        "    model.eval()\n",
        "\n",
        "    for x, y, target in test_dataloader:\n",
        "        x, y, target = x.to(device), y.to(device), target.to(device)\n",
        "\n",
        "        predict = model(x)\n",
        "        predict = F.log_softmax(predict, dim=-2)\n",
        "\n",
        "        loss = calculate_loss(predict, y)\n",
        "\n",
        "        predict = torch.argmax(predict, dim=-2)\n",
        "\n",
        "        for predict_item, y_item in zip(predict, target):\n",
        "            accurate += getSimilar(predict_item, y_item)/(MAX_LEN*BATCH_SIZE)\n",
        "            hard_accurate += getCorrect(predict_item, y_item)/(BATCH_SIZE)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "    accurate /= len(test_dataloader)\n",
        "    hard_accurate /= len(test_dataloader)\n",
        "\n",
        "    if epoch != None:\n",
        "        print(f\"[Epoch {epoch}] Train Loss : {train_loss} & Test Loss : {test_loss} & Accurate : {accurate*100}% & Hard-Accurate : {hard_accurate*100}%\")\n",
        "\n",
        "    return train_loss, test_loss\n"
      ],
      "metadata": {
        "id": "LmpC8B0isTwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "for epoch in range(START_EPOCH, START_EPOCH+EPOCHS):\n",
        "    train_loss, test_loss = train_one_epoch(model, optimizer, train_dataloader, test_dataloader, epoch=epoch)\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "    test_loss_list.append(test_loss)"
      ],
      "metadata": {
        "id": "c07LCd7RtFGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(list(range(START_EPOCH, START_EPOCH+EPOCHS)))\n",
        "plt.plot(x, np.array(train_loss_list),label='train')\n",
        "plt.plot(x, np.array(test_loss_list),label='test')\n",
        "plt.xlim([1, EPOCHS])\n",
        "plt.title(f\"Loss of IRT\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "14T0aexawyv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "            'epoch': START_EPOCH+EPOCHS-1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, 'Checkpoint.pth')"
      ],
      "metadata": {
        "id": "ZRUjKI_nw2Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# тестирование"
      ],
      "metadata": {
        "id": "q5bRZY4Mye8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"predict_text target_text\")\n",
        "\n",
        "for ind, (x, _, y) in enumerate(test_dataloader):\n",
        "    if ind > 10:\n",
        "        break\n",
        "    old_time = time.time()\n",
        "    predict_text, target_text = evalSample(model, x, y)\n",
        "    print(predict_text, target_text)"
      ],
      "metadata": {
        "id": "QQH9Dr-hxDEM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}